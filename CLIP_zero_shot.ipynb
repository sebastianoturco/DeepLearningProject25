{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYQiprE0pcVD"
      },
      "source": [
        "# CLIP zero-shot Evaluation\n",
        "This short notebook implements the dataset split into base and novel categories (see project assignment) and runs the zero-shot evaluation with CLIP.\n",
        "Feel free to copy the code contained in this notebook or to directly use this notebook as starting point for you project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UzXtFjhh7iOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1be2475-c7d9-40a9-f814-2c31e30ac7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai_clip in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from openai_clip) (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from openai_clip) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai_clip) (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->openai_clip) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# we need to install clip as it is not pre-installed\n",
        "# you are also free to use open_clip which provide more models\n",
        "# https://github.com/mlfoundations/open_clip\n",
        "%pip install openai_clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QtqdSOr8qqOn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import clip\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2353MHw1p24h"
      },
      "source": [
        "## Dataset Loading\n",
        "Let's get the data directly from torchvision as we have seen during labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "M_1CrUhZpVCq"
      },
      "outputs": [],
      "source": [
        "def get_data(data_dir=\"./data\", transform=None):\n",
        "    \"\"\"Load Flowers102 train, validation and test sets.\n",
        "    Args:\n",
        "        data_dir (str): Directory where the dataset will be stored.\n",
        "        transform (torch.Compose)\n",
        "    Returns:\n",
        "        tuple: A tuple containing the train, validation, and test sets.\n",
        "    \"\"\"\n",
        "    train = torchvision.datasets.Flowers102(root=data_dir, split=\"train\", download=True, transform=transform)\n",
        "    val = torchvision.datasets.Flowers102(root=data_dir, split=\"val\", download=True, transform=transform)\n",
        "    test = torchvision.datasets.Flowers102(root=data_dir, split=\"test\", download=True, transform=transform)\n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJI_a5EizA5a"
      },
      "source": [
        "## Base and Novel categories\n",
        "To split in base and novel categories we list all dataset classes, and count their number (we already know it's 102 but let's do it properly).\n",
        "Then, we just allocate the first half to base categories and the remaining half to novel ones.\n",
        "We can do this because we are simulating a real world application, but keep in mind this will not happen out there!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nfq51vd8q_5a"
      },
      "outputs": [],
      "source": [
        "def base_novel_categories(dataset):\n",
        "    # set returns the unique set of all dataset classes\n",
        "    all_classes = set(dataset._labels)\n",
        "    # and let's count them\n",
        "    num_classes = len(all_classes)\n",
        "\n",
        "    # here list(range(num_classes)) returns a list from 0 to num_classes - 1\n",
        "    # then we slice the list in half and generate base and novel category lists\n",
        "    base_classes = list(range(num_classes))[:num_classes//2]\n",
        "    novel_classes = list(range(num_classes))[num_classes//2:]\n",
        "    return base_classes, novel_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvDdoYQr2fIu"
      },
      "source": [
        "## Inspect Classes\n",
        "Let's now visualize which are the base and novel classes.\n",
        "To do so, we first get a dummy test set (without augmentations) as we are just interested in the dataset labels. Then, we split it useing `base_novel_categories`.\n",
        "Finally, we use the hard-coded CLASS_NAMES to print the class in natural language.\n",
        "\n",
        "> Note: the list of class names was only recently added to `torchvision.datasets.Flowers102`. To avoid useless errors that can occour to you, we decided to also provide such a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veGGpNDctCgR",
        "outputId": "dbbe9480-8cb5-4e69-cc84-128fd02d5b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Class Names: [(0, 'pink primrose'), (1, 'hard-leaved pocket orchid'), (2, 'canterbury bells'), (3, 'sweet pea'), (4, 'english marigold'), (5, 'tiger lily'), (6, 'moon orchid'), (7, 'bird of paradise'), (8, 'monkshood'), (9, 'globe thistle'), (10, 'snapdragon'), (11, \"colt's foot\"), (12, 'king protea'), (13, 'spear thistle'), (14, 'yellow iris'), (15, 'globe-flower'), (16, 'purple coneflower'), (17, 'peruvian lily'), (18, 'balloon flower'), (19, 'giant white arum lily'), (20, 'fire lily'), (21, 'pincushion flower'), (22, 'fritillary'), (23, 'red ginger'), (24, 'grape hyacinth'), (25, 'corn poppy'), (26, 'prince of wales feathers'), (27, 'stemless gentian'), (28, 'artichoke'), (29, 'sweet william'), (30, 'carnation'), (31, 'garden phlox'), (32, 'love in the mist'), (33, 'mexican aster'), (34, 'alpine sea holly'), (35, 'ruby-lipped cattleya'), (36, 'cape flower'), (37, 'great masterwort'), (38, 'siam tulip'), (39, 'lenten rose'), (40, 'barbeton daisy'), (41, 'daffodil'), (42, 'sword lily'), (43, 'poinsettia'), (44, 'bolero deep blue'), (45, 'wallflower'), (46, 'marigold'), (47, 'buttercup'), (48, 'oxeye daisy'), (49, 'common dandelion'), (50, 'petunia')]\n",
            "Novel Class Names: [(51, 'wild pansy'), (52, 'primula'), (53, 'sunflower'), (54, 'pelargonium'), (55, 'bishop of llandaff'), (56, 'gaura'), (57, 'geranium'), (58, 'orange dahlia'), (59, 'pink-yellow dahlia?'), (60, 'cautleya spicata'), (61, 'japanese anemone'), (62, 'black-eyed susan'), (63, 'silverbush'), (64, 'californian poppy'), (65, 'osteospermum'), (66, 'spring crocus'), (67, 'bearded iris'), (68, 'windflower'), (69, 'tree poppy'), (70, 'gazania'), (71, 'azalea'), (72, 'water lily'), (73, 'rose'), (74, 'thorn apple'), (75, 'morning glory'), (76, 'passion flower'), (77, 'lotus'), (78, 'toad lily'), (79, 'anthurium'), (80, 'frangipani'), (81, 'clematis'), (82, 'hibiscus'), (83, 'columbine'), (84, 'desert-rose'), (85, 'tree mallow'), (86, 'magnolia'), (87, 'cyclamen'), (88, 'watercress'), (89, 'canna lily'), (90, 'hippeastrum'), (91, 'bee balm'), (92, 'ball moss'), (93, 'foxglove'), (94, 'bougainvillea'), (95, 'camellia'), (96, 'mallow'), (97, 'mexican petunia'), (98, 'bromelia'), (99, 'blanket flower'), (100, 'trumpet creeper'), (101, 'blackberry lily')]\n"
          ]
        }
      ],
      "source": [
        "_, _, tmp_test = get_data()\n",
        "base_classes, novel_classes = base_novel_categories(tmp_test)\n",
        "CLASS_NAMES = [\"pink primrose\", \"hard-leaved pocket orchid\", \"canterbury bells\", \"sweet pea\", \"english marigold\", \"tiger lily\", \"moon orchid\", \"bird of paradise\", \"monkshood\", \"globe thistle\", \"snapdragon\", \"colt's foot\", \"king protea\", \"spear thistle\", \"yellow iris\", \"globe-flower\", \"purple coneflower\", \"peruvian lily\", \"balloon flower\", \"giant white arum lily\", \"fire lily\", \"pincushion flower\", \"fritillary\", \"red ginger\", \"grape hyacinth\", \"corn poppy\", \"prince of wales feathers\", \"stemless gentian\", \"artichoke\", \"sweet william\", \"carnation\", \"garden phlox\", \"love in the mist\", \"mexican aster\", \"alpine sea holly\", \"ruby-lipped cattleya\", \"cape flower\", \"great masterwort\", \"siam tulip\", \"lenten rose\", \"barbeton daisy\", \"daffodil\", \"sword lily\", \"poinsettia\", \"bolero deep blue\", \"wallflower\", \"marigold\", \"buttercup\", \"oxeye daisy\", \"common dandelion\", \"petunia\", \"wild pansy\", \"primula\", \"sunflower\", \"pelargonium\", \"bishop of llandaff\", \"gaura\", \"geranium\", \"orange dahlia\", \"pink-yellow dahlia?\", \"cautleya spicata\", \"japanese anemone\", \"black-eyed susan\", \"silverbush\", \"californian poppy\", \"osteospermum\", \"spring crocus\", \"bearded iris\", \"windflower\", \"tree poppy\", \"gazania\", \"azalea\", \"water lily\", \"rose\", \"thorn apple\", \"morning glory\", \"passion flower\", \"lotus\", \"toad lily\", \"anthurium\", \"frangipani\", \"clematis\", \"hibiscus\", \"columbine\", \"desert-rose\", \"tree mallow\", \"magnolia\", \"cyclamen\", \"watercress\", \"canna lily\", \"hippeastrum\", \"bee balm\", \"ball moss\", \"foxglove\", \"bougainvillea\", \"camellia\", \"mallow\", \"mexican petunia\", \"bromelia\", \"blanket flower\", \"trumpet creeper\", \"blackberry lily\"]\n",
        "print(\"Base Class Names:\", [(i, CLASS_NAMES[i]) for i in base_classes])\n",
        "print(\"Novel Class Names:\", [(i, CLASS_NAMES[i]) for i in novel_classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8puO1VNpzwvi"
      },
      "source": [
        "## Split Dataset\n",
        "The next step is to actually split the dataset into the base and novel categories we extract from `base_novel_categories`.\n",
        "To split the data we need the dataset (obviously) and the list of base classes. If the sample label is not part of the base categories, then it must be part of the novel ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "msOszMs2zRRu"
      },
      "outputs": [],
      "source": [
        "def split_data(dataset, base_classes):\n",
        "    # these two lists will store the sample indexes\n",
        "    base_categories_samples = []\n",
        "    novel_categories_samples = []\n",
        "\n",
        "    # we create a set of base classes to compute the test below in O(1)\n",
        "    # this is optional and can be removed\n",
        "    base_set = set(base_classes)\n",
        "\n",
        "    # here we iterate over sample labels and also get the correspondent sample index\n",
        "    for sample_id, label in enumerate(dataset._labels):\n",
        "        if label in base_set:\n",
        "            base_categories_samples.append(sample_id)\n",
        "        else:\n",
        "            novel_categories_samples.append(sample_id)\n",
        "\n",
        "    # here we create the dataset subsets\n",
        "    # the torch Subset is just a wrapper around the dataset\n",
        "    # it simply stores the subset indexes and the original dataset (your_subset.dataset)\n",
        "    # when asking for sample i in the subset, torch will look for its original position in the dataset and retrieve it\n",
        "    # https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset\n",
        "    base_dataset = torch.utils.data.Subset(dataset, base_categories_samples)\n",
        "    novel_dataset = torch.utils.data.Subset(dataset, novel_categories_samples)\n",
        "    return base_dataset, novel_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQZT22rE8hBw"
      },
      "source": [
        "## Extract k shots\n",
        "As the dataset already provides 10 train and validation shots, we do not need to extract them.\n",
        "Beaware that Few-Shot Adaptation papers must do this operation as most datasets count significantly more samples in both the training and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KpbPRLr7WL_"
      },
      "source": [
        "## Load CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh6uLZRT7YJx",
        "outputId": "63605745-d158-4d8f-b6f3-98ae8b01984a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)\n",
              "    CenterCrop(size=(224, 224))\n",
              "    <function _convert_image_to_rgb at 0x7f02719f7ec0>\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# available models = ['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n",
        "model, preprocess = clip.load(\"ViT-B/16\", device=device)\n",
        "\n",
        "# preprocess contains CLIP's pre-defined augmentations, let's inspect them!\n",
        "preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM9H14899ses"
      },
      "source": [
        "## Load and Prepare Data\n",
        "Here we get the three dataset split and pass clip pre-defined augmentations.\n",
        "Then, we compute base and novel categories (in this case is redundand as we already did it before).\n",
        "Finally, se split the three datasets into base and novel categories.\n",
        "As we want to use the novel categories only for the test set, we drop `train_novel` and `val_novel`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TVrYUYTv9ttM"
      },
      "outputs": [],
      "source": [
        "# get the three datasets\n",
        "train_set, val_set, test_set = get_data(transform=preprocess)\n",
        "\n",
        "# split classes into base and novel\n",
        "base_classes, novel_classes = base_novel_categories(train_set)\n",
        "\n",
        "# split the three datasets\n",
        "train_base, _ = split_data(train_set, base_classes)\n",
        "val_base, _ = split_data(val_set, base_classes)\n",
        "test_base, test_novel = split_data(test_set, base_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcgMwr3J9VIg"
      },
      "source": [
        "## Compute Zero-Shot Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7uhblkvm9US4",
        "outputId": "11b513e2-5d4b-4284-f1e5-037764fe4d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Zero-shot evaluation on Base Classes:   0%|          | 0/20 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-be78d1eccf8d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mbase_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"🧠 Zero-shot evaluation on Base Classes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mnovel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_novel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnovel_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"🧠 Zero-shot evaluation on Novel Classes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-be78d1eccf8d>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, dataset, categories, batch_size, device, label)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# here we store the number of correct predictions we will make\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# base categories range from 0 to 50, whil novel ones from 51 to 101\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# therefore we must map categories to the [0, 50], otherwise we will have wrong predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "@torch.no_grad() # we don't want gradients\n",
        "def eval(model, dataset, categories, batch_size, device, label=\"\"):\n",
        "    # let's set the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Remap labels into a contiguous set starting from zero\n",
        "    contig_cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
        "\n",
        "    # here we apply the standard CLIP template used for oxford flowers to all categories\n",
        "    # and immediately tokenize each sentence (convert natural language into numbers - feel free to print the text input to inspect them)\n",
        "    text_inputs = clip.tokenize(\n",
        "        [f\"a photo of a {CLASS_NAMES[c]}, a type of flower.\" for c in categories]\n",
        "    ).to(device)\n",
        "\n",
        "    # we can encode the text features once as they are shared for all images\n",
        "    # therefore we do it outside the evaluation loop\n",
        "    text_features = model.encode_text(text_inputs)\n",
        "    # and here we normalize them (standard pratice with CLIP)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True) # per avere norma 1 per calcolare cosine similarity\n",
        "\n",
        "    # simple dataloader creation\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # here we store the number of correct predictions we will make\n",
        "    correct_predictions = 0\n",
        "    for image, target in tqdm(dataloader, desc=label):\n",
        "        # base categories range from 0 to 50, whil novel ones from 51 to 101\n",
        "        # therefore we must map categories to the [0, 50], otherwise we will have wrong predictions\n",
        "        # Map targets in contiguous set starting from zero\n",
        "        # Labels needs to be .long() in pytorch\n",
        "        target = torch.Tensor([contig_cat2idx[t.item()] for t in target]).long()\n",
        "\n",
        "        image = image.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # forward image through CLIP image encoder\n",
        "        image_features = model.encode_image(image)\n",
        "        # and normalize\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # here cosine similarity between image and text features and keep the argmax for every row (every image)\n",
        "        predicted_class = (image_features @ text_features.T).argmax(dim=-1)\n",
        "        # now we check which are correct, and sum them (False == 0, True == 1)\n",
        "        correct_predictions += (predicted_class == target).sum().item()\n",
        "\n",
        "    # and now we compute the accuracy\n",
        "    accuracy = correct_predictions / len(dataset)\n",
        "    return accuracy\n",
        "\n",
        "base_accuracy = eval(model=model, dataset=test_base, categories=base_classes, batch_size=128, device=device, label=\"🧠 Zero-shot evaluation on Base Classes\")\n",
        "novel_accuracy = eval(model=model, dataset=test_novel, categories=novel_classes, batch_size=128, device=device, label=\"🧠 Zero-shot evaluation on Novel Classes\")\n",
        "\n",
        "print()\n",
        "print(f\"🔍 Base classes accuracy: {base_accuracy*100:.2f}%\")\n",
        "print(f\"🔍 Novel classes accuracy: {novel_accuracy*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baYfLKNdfbUR"
      },
      "source": [
        "## Harmonic Mean\n",
        "Few-Shot Adaptations papers usually report the Harmonic Mean.\n",
        "The harmonic mean tends to mitigate the impact of large outliers (base accuracy) and aggravate the impact of small ones (novel accuracy).\n",
        "Thus, achieving very high base accuracies at the expense of the novel accuracy will be penalized by the HM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKAXR7hlfbUR",
        "outputId": "e00e50f4-3b0f-4e79-ed09-e8e82cc53668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Harmonic Mean: 74.62%\n"
          ]
        }
      ],
      "source": [
        "def harmonic_mean(base_accuracy, novel_accuracy):\n",
        "    numerator = 2\n",
        "    denominator = 1 / base_accuracy + 1 / novel_accuracy\n",
        "    hm = numerator / denominator\n",
        "    return hm\n",
        "\n",
        "print(f\"🔍 Harmonic Mean: {harmonic_mean(base_accuracy, novel_accuracy)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "CfzZ1Es-MwF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ad2809-930f-4dcb-ced9-b9b8a0bba09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "First Image : torch.Size([1, 512])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:   2%|▏         | 1/64 [00:00<00:24,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[-0.3425, -1.3994,  0.3904,  ..., -0.0151,  0.0814,  0.1364],\n",
            "        [-0.2925, -1.2959,  0.3948,  ..., -0.0690,  0.0093,  0.1982],\n",
            "        [-0.3127, -1.0732,  0.2690,  ..., -0.0573,  0.5474,  0.3918],\n",
            "        ...,\n",
            "        [ 0.3533, -1.0342,  0.1299,  ..., -0.1173, -0.1705,  0.1230],\n",
            "        [-0.4597, -1.2852,  0.2913,  ...,  0.0812,  0.4585,  0.1615],\n",
            "        [-0.3120, -0.9443,  0.3528,  ..., -0.0821,  0.1870,  0.3259]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(3.8340, device='cuda:0', dtype=torch.float16,\n",
            "       grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  11%|█         | 7/64 [00:00<00:04, 13.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  17%|█▋        | 11/64 [00:00<00:03, 13.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  20%|██        | 13/64 [00:01<00:03, 14.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  28%|██▊       | 18/64 [00:01<00:02, 15.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  34%|███▍      | 22/64 [00:01<00:02, 15.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  41%|████      | 26/64 [00:01<00:02, 15.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  47%|████▋     | 30/64 [00:02<00:02, 15.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  53%|█████▎    | 34/64 [00:02<00:01, 17.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  58%|█████▊    | 37/64 [00:02<00:01, 17.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  62%|██████▎   | 40/64 [00:02<00:01, 17.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  69%|██████▉   | 44/64 [00:03<00:01, 15.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  77%|███████▋  | 49/64 [00:03<00:00, 17.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  80%|███████▉  | 51/64 [00:03<00:00, 16.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  86%|████████▌ | 55/64 [00:03<00:00, 16.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  94%|█████████▍| 60/64 [00:03<00:00, 16.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes: 100%|██████████| 64/64 [00:04<00:00, 15.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Epoch 1, Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:   5%|▍         | 3/64 [00:00<00:07,  8.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  11%|█         | 7/64 [00:00<00:04, 12.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  17%|█▋        | 11/64 [00:00<00:03, 14.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  20%|██        | 13/64 [00:01<00:03, 13.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  27%|██▋       | 17/64 [00:01<00:03, 13.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  33%|███▎      | 21/64 [00:01<00:02, 15.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  36%|███▌      | 23/64 [00:01<00:03, 13.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  42%|████▏     | 27/64 [00:02<00:02, 13.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  45%|████▌     | 29/64 [00:02<00:02, 14.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  55%|█████▍    | 35/64 [00:02<00:01, 15.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  61%|██████    | 39/64 [00:02<00:01, 14.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  64%|██████▍   | 41/64 [00:02<00:01, 14.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  73%|███████▎  | 47/64 [00:03<00:01, 15.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  77%|███████▋  | 49/64 [00:03<00:00, 15.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  84%|████████▍ | 54/64 [00:03<00:00, 16.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  88%|████████▊ | 56/64 [00:03<00:00, 15.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes:  92%|█████████▏| 59/64 [00:04<00:00, 16.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🧠 Finetuining training on Base Classes:  98%|█████████▊| 63/64 [00:04<00:00, 14.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        ...,\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n",
            "Image: tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan],\n",
            "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
            "       dtype=torch.float16, grad_fn=<MmBackward0>)\n",
            "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🧠 Finetuining training on Base Classes: 100%|██████████| 64/64 [00:04<00:00, 14.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "categories = base_classes\n",
        "dataset = train_base\n",
        "batch_size = 8\n",
        "label = \"🧠 Finetuining training on Base Classes\"\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "# Get a single batch\n",
        "images, labels = next(iter(dataloader))\n",
        "\n",
        "# Access the first image in the batch\n",
        "print(images[0].shape)\n",
        "first_image = images[0].to(device)\n",
        "first_image = first_image.unsqueeze(0)\n",
        "\n",
        "\n",
        "print(f\"First Image : {model.encode_image(first_image).shape}\")\n",
        "visual_projection = model.visual.proj\n",
        "\n",
        "# Freeze all parameters in the model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze the projection layer\n",
        "visual_projection.requires_grad = True\n",
        "#train_loader = DataLoader(train_base, batch_size=32, shuffle=True)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = Adam([visual_projection], lr=1e-4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "contig_cat2idx = {cat: idx for idx, cat in enumerate(categories)}\n",
        "\n",
        "\n",
        "text_inputs = clip.tokenize(\n",
        "        [f\"a photo of a {CLASS_NAMES[c]}, a type of flower.\" for c in categories]).to(device)\n",
        "\n",
        "\n",
        "text_features = model.encode_text(text_inputs)\n",
        "    # and here we normalize them (standard pratice with CLIP)\n",
        "text_features /= text_features.norm(dim=-1, keepdim=True) # per avere norma 1 per calcolare cosine similarity\n",
        "\n",
        "    # simple dataloader creation\n",
        "\n",
        "\n",
        "\n",
        "    # here we store the number of correct predictions we will make\n",
        "#correct_predictions = 0\n",
        "num_epochs= 2\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for image, target in tqdm(dataloader, desc=label):\n",
        "\n",
        "        # base categories range from 0 to 50, whil novel ones from 51 to 101\n",
        "        # therefore we must map categories to the [0, 50], otherwise we will have wrong predictions\n",
        "        # Map targets in contiguous set starting from zero\n",
        "        # Labels needs to be .long() in pytorch\n",
        "        #print(len(dataloader))\n",
        "        target = torch.Tensor([contig_cat2idx[t.item()] for t in target]).long()\n",
        "\n",
        "        image = image.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # forward image through CLIP image encoder\n",
        "        image_features = model.encode_image(image)\n",
        "        print(f\"Image: {image_features}\")\n",
        "        # and normalize\n",
        "        image_features_norm = image_features.norm(dim=-1, keepdim=True)\n",
        "        image_features_norm = torch.clamp(image_features_norm, min=1e-6)\n",
        "        image_features = image_features / image_features_norm\n",
        "        #print(f\"Image: {image}\")\n",
        "        #print(f\"text: {text_features}\")\n",
        "\n",
        "        # here cosine similarity between image and text features and keep the argmax for every row (every image)\n",
        "        logits = image_features @ text_features.T\n",
        "\n",
        "        loss = criterion(logits, target)\n",
        "        print(loss)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "  print(f\"Epoch {epoch + 1}, Loss: {total_loss/ len(dataloader)}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}